# Continuous Envs
bipedal1:
  env_id: BipedalWalker-v3
  input_model_name: bipedal1
  output_model_name: TEST
  render: False
  state_dim: 24
  action_dim: 4
  action_low: -1
  action_high: 1
  replay_memory_size: 100000
  batch_size: 28
  discount: 0.99
  tau: 0.005
  learning_rate: 0.0003
  policy_noise: 0.2
  noise_clip: 0.5
  policy_freq: 1
  model_save_freq: 100
  total_it: 0
  max_reward: 300
  max_timestep: 1600
  max_episodes: 30000
  alpha: 0.2
  entropy_coefficient: 4
  minimum_entropy: 3.8
  entropy_decay: 0.99
  env_make_params:
    hardcore: False

bipedal2:
  env_id: BipedalWalker-v3
  input_model_name: bipedal3
  output_model_name: bipedal4
  render: False
  state_dim: 24
  action_dim: 4
  action_low: -1
  action_high: 1
  replay_memory_size: 100000
  batch_size: 128
  discount: 0.99
  tau: 0.005
  learning_rate: 0.0003
  policy_noise: 0.2
  noise_clip: 0.5
  policy_freq: 2
  model_save_freq: 100
  total_it: 0
  max_reward: 300
  max_timestep: 1600
  max_episodes: 3000
  alpha: 0.2
  entropy_coefficient: 3
  minimum_entropy: 0.05
  entropy_decay: 0.9995
  env_make_params:
    hardcore: False


pendulum1:
  env_id: Pendulum-v1
  input_model_name: pendulum20
  output_model_name: pendulum20
  render: False
  state_dim: 3
  action_dim: 1
  action_low: -2
  action_high: 2
  replay_memory_size: 100000
  batch_size: 100
  discount: 0.99
  tau: 0.005
  learning_rate: 0.0003
  policy_noise: 0.2
  noise_clip: 0.5
  policy_freq: 2
  model_save_freq: 100
  total_it: 0
  max_reward: 0
  max_timestep: 200
  max_episodes: 20000
  alpha: 0.2
  entropy_coefficient: 0.5
  minimum_entropy: 0.001
  entropy_decay: 0.9995
  env_make_params:
    g: 9.8

pendulum2:
  env_id: Pendulum-v1
  input_model_name: 
  output_model_name: pendulum1
  render: False
  state_dim: 3
  action_dim: 1
  action_low: -2
  action_high: 2
  replay_memory_size: 100000
  batch_size: 100
  discount: 0.99
  tau: 0.005
  learning_rate: 0.0003
  policy_noise: 0.2
  noise_clip: 0.5
  policy_freq: 2
  model_save_freq: 100
  total_it: 0
  max_reward: 0
  max_timestep: 200
  max_episodes: 3000
  alpha: 0.2
  entropy_coefficient: 10
  minimum_entropy: 0.05
  entropy_decay: 0.9998
  env_make_params:
    g: 9.8


# Discrete Envs
cartpole1:
  env_id: CartPole-v1
  input_model_name: cartpole2
  output_model_name: cartpole3
  render: False
  state_dim: 4
  action_dim: 2
  action_low: 0
  action_high: 1
  replay_memory_size: 10000
  batch_size: 256
  discount: 0.99
  tau: 0.005
  learning_rate: 0.0001
  policy_noise: 0.2
  noise_clip: 0.5
  policy_freq: 2
  model_save_freq: 100
  total_it: 0
  max_reward: 1000
  max_timestep: 500
  max_episodes: 3000
  alpha: 0.01
  entropy_coefficient: 2
  minimum_entropy: 0.05
  entropy_decay: 0.9999

flappybird:
  env_id: FlappyBird-v0
  input_model_name: FLAPPYBIRD1
  output_model_name: FLAPPPYBIRD1
  render: False
  state_dim: 12
  action_dim: 2
  action_low: 0
  action_high: 1
  replay_memory_size: 10000
  batch_size: 256
  discount: 0.99
  tau: 0.005
  learning_rate: 0.0001
  policy_noise: 0.2
  noise_clip: 0.5
  policy_freq: 2
  model_save_freq: 100
  total_it: 0
  max_reward: 1000
  max_timestep: 500
  max_episodes: 3000
  alpha: 0.2
  entropy_coefficient: 2
  minimum_entropy: 1.6
  entropy_decay: 0.999
  env_make_params:
    use_lidar: False


lundarlanding:
  env_id: LunarLander-v2
  input_model_name: 
  output_model_name: lundarlanding1
  render: False
  state_dim: 8
  action_dim: 4
  action_low: 0
  action_high: 4
  replay_memory_size: 100000
  batch_size: 100
  discount: 0.99
  tau: 0.005
  learning_rate: 0.001
  policy_noise: 0.2
  noise_clip: 0.5
  policy_freq: 2
  model_save_freq: 100
  total_it: 0
  max_reward: 1000
  max_timestep: 2000
  max_episodes: 3000
  alpha: 0.2
  entropy_coefficient: 1
  minimum_entropy: 0.01
  entropy_decay: 0.9998
  env_make_params:
    continuous: False
    gravity: -10
    enable_wind: False
    wind_power: 5.0
    turbulence_power: 1.5

lunarlanding2:
  env_id: LunarLander-v2
  input_model_name: 
  output_model_name: lundarlanding2
  render: False
  state_dim: 8
  action_dim: 4
  action_low: 0
  action_high: 4
  replay_memory_size: 100000
  batch_size: 100
  discount: 0.99
  tau: 0.005
  learning_rate: 0.0005
  policy_noise: 0.2
  noise_clip: 0.5
  policy_freq: 2
  model_save_freq: 100
  total_it: 0
  max_reward: 1000
  max_timestep: 1000
  max_episodes: 3000
  alpha: 0.2
  entropy_coefficient: 1
  minimum_entropy: 0.01
  entropy_decay: 0.999
  env_make_params:
    continuous: False
    gravity: -10
    enable_wind: False
    wind_power: 5.0
    turbulence_power: 1.5




acrobot:
  env_id: Acrobot-v1
  input_model_name: acrobot1
  output_model_name: acrobot1
  render: False
  state_dim: 6
  action_dim: 3
  action_low: 0
  action_high: 3
  replay_memory_size: 10000
  batch_size: 256
  discount: 0.99
  tau: 0.005
  learning_rate: 0.0003
  policy_noise: 0.2
  noise_clip: 0.5
  policy_freq: 2
  model_save_freq: 100
  total_it: 0
  max_reward: 1000
  max_timestep: 500
  max_episodes: 3000
  alpha: 0.2
  entropy_coefficient: 2
  minimum_entropy: 0.05
  entropy_decay: 0.9999




